{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6545f4c-5e2d-48a6-88d0-4272ab9bf33c",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "```\n",
    "                                         1.2 Create an archive\n",
    "\n",
    "                                       ┌──────────────────────┐\n",
    "                                       │                      │\n",
    "                                       │   Torchserve Model   │\n",
    "                                       │       Archive        │\n",
    "                                       │                      │\n",
    "                                       │   ┌──────────────┐   │   ┌──────────────┐\n",
    "                                       │   │   model.py   │   │   │              │              1.3\n",
    "      1.1.1 from lab3   ───────────────┼─► ├──────────────┤   │   │  Torchserve  │              # workers\n",
    "                                       │   │ one_layer.pt │   │   │              │ ◄──────────  # batchsize\n",
    "                                       │   └──────────────┘   │   │    config    │              max batch delay\n",
    "                                       │                      │   │              │              etc.\n",
    "        preprocess  code               │   ┌──────────────┐   │   └──────┬───────┘\n",
    "1.1.2      call model     ─────────────┼─► │  handler.py  │   │          │\n",
    "        postprocess code               │   └──────────────┘   │          │\n",
    "                                       │                      │          │\n",
    "                                       └──────────┬───────────┘          │\n",
    "                                                  │                      │\n",
    "                                                  │                      │\n",
    "                                                  │                      │\n",
    "                                       ┌──────────▼──────────────────────▼───────┐\n",
    "                                       │                                         │    1.4 Upload to storage\n",
    "                                       │   Storage   ( MinIO / S3 / Url / PVC )  │\n",
    "                                       │                                         │\n",
    "                                       └────────────────────┬────────────────────┘\n",
    "                                                            │\n",
    "                                       ┌────────────────────▼────────────────────┐\n",
    "                                       │                                         │    2 Define KServe Yaml\n",
    "                                       │             KServe Predictor            │\n",
    "                                       │                                         │    3 Do some basic testing\n",
    "                                       │             ( scaling pods )            │\n",
    "                                       │                                         │    4 Autoscaling\n",
    "                                       └─────────────────────────────────────────┘\n",
    "                                                                                      5 Canary Rollout\n",
    "     \n",
    " ```\n",
    " \n",
    "The lab mainly covers:\n",
    "- PyTorch Serve: package PyTorch model with custom preprocess/postprocess functions\n",
    "- MinIO storage usage\n",
    "- KServe: basic, autoscaling, canary rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5610b8-6dce-41a9-8ab9-95cad9296bb5",
   "metadata": {},
   "source": [
    "## 1 PyTorch Serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b55886e",
   "metadata": {},
   "source": [
    "#### 1.1 Prepartion for Model Archiver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b721d1",
   "metadata": {},
   "source": [
    "Prepare 3 files:\n",
    "- pytorch_one_layer.pt: a serialized file (.pt or .pth) should be a checkpoint in case of torchscript and state_dict in case of eager mode.\n",
    "- model.py: a model file should contain the model architecture. This file is mandatory in case of eager mode models.\n",
    "- handler.py: codes for model initialization, pre-processing, post-processing, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ceb73",
   "metadata": {},
   "source": [
    "##### 1.1.1 pytorch_one_layer.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c0fec",
   "metadata": {},
   "source": [
    "I have already uploaded it in https://github.com/vmware/ml-ops-platform-for-vsphere/tree/main/website/content/en/docs/kubeflow-tutorial/lab4_files/pytorch_one_layer.pt, which comes from [Lab3](../lab3.md):\n",
    "\n",
    "```python\n",
    "if RANK == 0:\n",
    "    print(\"saving model to\", args.dir)\n",
    "    os.makedirs(args.dir, exist_ok=True) \n",
    "    torch.save(model.state_dict(), os.path.join(args.dir, \"pytorch_one_layer.pt\"))\n",
    "```\n",
    "\n",
    "<span style=\"color:red\">If you are using JupyterLab in Kubeflow, remember to upload it to `torchserve/pytorch_one_layer.pt`</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0932219",
   "metadata": {},
   "source": [
    "##### 1.1.2 model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c186e",
   "metadata": {},
   "source": [
    "The pytorch_one_layer.pt does not contains model architecture, we need to provide model architecture definition with torchserve.\n",
    "\n",
    "Learn more about eager-mode vs torchscript here:\n",
    "https://pytorch.org/tutorials/beginner/deploy_seq2seq_hybrid_frontend_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa04231",
   "metadata": {},
   "source": [
    "Copy model architecture class `class Net(nn.Module)` from Lab3 to the cell below. \n",
    "\n",
    "Just run the cell and the code inside will be saved into `torchserve/model.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aca787f-7038-4e2d-a973-494ba27d5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p torchserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119fa2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting torchserve/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile torchserve/model.py\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f8e44",
   "metadata": {},
   "source": [
    "##### 1.1.3 Handler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6fad86",
   "metadata": {},
   "source": [
    "What can handler.py do? (https://pytorch.org/serve/custom_service.html)\n",
    "\n",
    "- Initialize the model instance\n",
    "- Pre-process input data before it is sent to the model for inference or Captum explanations\n",
    "- Customize how the model is invoked for inference or explanations\n",
    "- Post-process output from the model before sending back a response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54349697",
   "metadata": {},
   "source": [
    "Implement `preprocess` and `postprocess` functions with the reference of `lab2` &  `lab3` \n",
    "- Preprocess: [Feature Extraction in lab2]\n",
    "- Postprocess: [PyTorch code in lab3]\n",
    "\n",
    "Just run the cell and the code inside will be saved into `torchserve/handler.py`\n",
    "\n",
    "The data flow:\n",
    "   ```json\n",
    "   {\"instances\": [\"This is the first email\"]}\n",
    "\n",
    "   {\"instances\": [\"This is the second email\"]}\n",
    "   ```\n",
    "   ↓↓↓  torchserve web server: combines multiple HTTP request into batches, forward batch requests to `Handler.py`\n",
    "   ```python\n",
    "   [\n",
    "      \"This is the first email\",\n",
    "      \"This is the second email\",\n",
    "   ]\n",
    "   ```\n",
    "   ↓↓↓  Handler.py preprocess: convert list of dict into `torch tensor` for model inference\n",
    "   ```python\n",
    "   [\n",
    "      [0, 0, 0, 0, 0],\n",
    "      [1, 1, 1, 1, 1],\n",
    "   ]\n",
    "   ```\n",
    "   ↓↓↓  PyTorch Model Inference\n",
    "   ```python\n",
    "   [\n",
    "      [0.5, -0.3],\n",
    "      [0.3, 0.8],\n",
    "   ]\n",
    "   ```\n",
    "   ↓↓↓  Handler.py postprocess\n",
    "   ```python\n",
    "   [\n",
    "      {'model_version': '1', 'prediction': 'ham'},\n",
    "      {'model_version': '1', 'prediction': 'spam'},\n",
    "   ]\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ddb6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting torchserve/handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile torchserve/handler.py\n",
    "# custom handler file\n",
    "\n",
    "# model_handler.py\n",
    "\n",
    "\"\"\"\n",
    "ModelHandler defines a custom model handler.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "\n",
    "# BaseHandler:\n",
    "# https://github.com/pytorch/serve/blob/master/ts/torch_handler/base_handler.py\n",
    "\n",
    "class ModelHandler(BaseHandler):\n",
    "    \"\"\"\n",
    "    A custom model handler implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def preprocess(self, batch):\n",
    "        \"\"\"\n",
    "        Transform raw input into model input data.\n",
    "        :param batch: list of raw requests, should match batch size\n",
    "        :return: list of preprocessed model input data\n",
    "        \"\"\"\n",
    "        feature_list = []\n",
    "        logging.info(\"[preprocess] batch received:\")\n",
    "        logging.info(batch)\n",
    "        for email in batch:\n",
    "            # extract features from email\n",
    "            feature = []\n",
    "            # short text\n",
    "            short_text = len(email) < 500\n",
    "            feature.append(int(short_text))\n",
    "            # high frequency words\n",
    "            high_frequency_words = [\"body\", \"business\", \"html\", \"money\"]\n",
    "            for word in high_frequency_words:\n",
    "                contain_bool = word in email\n",
    "                feature.append(int(contain_bool))\n",
    "\n",
    "            feature_list.append(feature)\n",
    "\n",
    "        logging.info(\"Preprocess result:\")\n",
    "        logging.info(feature_list)\n",
    "        return torch.as_tensor(feature_list, dtype=torch.float32, device=self.device)\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        \"\"\"\n",
    "        Return inference result.\n",
    "        :param inference_output: list of inference output\n",
    "        :return: list of predict results\n",
    "        \"\"\"\n",
    "        # Take output from network and post-process to desired format\n",
    "        logging.info(\"Logits from model:\")\n",
    "        logging.info(inference_output)\n",
    "\n",
    "        pred = inference_output.max(1)[1]\n",
    "        positive_dict = {\"version\": \"2\", \"prediction\": \"spam\"}\n",
    "        negative_dict = {\"version\": \"2\", \"prediction\": \"ham\"}\n",
    "        postprocess_result = list(map(\n",
    "                lambda x: positive_dict if x == 1 else negative_dict, \n",
    "                pred))\n",
    "\n",
    "        logging.info(\"Postprocess result:\")\n",
    "        logging.info(postprocess_result)\n",
    "        return postprocess_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82097fd3-c832-40da-90a6-8dd30f52ebc6",
   "metadata": {},
   "source": [
    "#### 1.2 Torchserve Model Archiver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8237c2-4dba-4428-9197-9140a393f9e9",
   "metadata": {},
   "source": [
    "It basically create a tar called `{model-name}.mar` from `model-file`, `serialized-file (*.pt)`, `handler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cfffb2d-3a0e-4642-912b-3a3bbe2e5c87",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch-model-archiver in /opt/conda/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.8/site-packages (from torch-model-archiver) (0.18.2)\n",
      "Requirement already satisfied: enum-compat in /opt/conda/lib/python3.8/site-packages (from torch-model-archiver) (0.0.3)\n",
      "create successfully\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd $(dirname $0)/torchserve\n",
    "base_path=$(pwd)\n",
    "\n",
    "mkdir -p $base_path/model-store && cd $base_path/model-store &&\n",
    "if [ -f $base_path/model-store/spam_email.mar ]; then\n",
    "    rm $base_path/model-store/spam_email.mar\n",
    "fi\n",
    "\n",
    "pip install torch-model-archiver -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "\n",
    "torch-model-archiver --model-name spam_email --version 1.0 \\\n",
    "--model-file $base_path/model.py \\\n",
    "--serialized-file $base_path/pytorch_one_layer.pt \\\n",
    "--handler $base_path/handler.py\n",
    "\n",
    "echo \"create successfully\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53742313-cfe9-4e29-b71e-9d7f92cfb606",
   "metadata": {},
   "source": [
    "#### 1.3 create torchserve config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eca6a9",
   "metadata": {},
   "source": [
    "Feel free to change the parameters:\n",
    "\n",
    "- minWorkers: the minimum number of workers of a model\n",
    "- maxWorkers: the maximum number of workers of a model\n",
    "- batchSize: the batch size of a model\n",
    "- maxBatchDelay: the maximum dalay in msec of a batch of a model\n",
    "- responseTimeout: the timeout in msec of a model's response\n",
    "- defaultVersion: the default version of a model\n",
    "- marName: the mar file name of a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a96fba-15da-44e1-bd4c-877dba5dcee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p torchserve/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55089cd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting torchserve/config/config.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile torchserve/config/config.properties\n",
    "\n",
    "inference_address=http://0.0.0.0:8085\n",
    "management_address=http://0.0.0.0:8085\n",
    "metrics_address=http://0.0.0.0:8082\n",
    "grpc_inference_port=7070\n",
    "grpc_management_port=7071\n",
    "enable_metrics_api=true\n",
    "metrics_format=prometheus\n",
    "number_of_netty_threads=4\n",
    "job_queue_size=10\n",
    "enable_envvars_config=true\n",
    "install_py_dep_per_model=true\n",
    "model_store=/home/model-server/torchserve_mar/spam_email/model-store\n",
    "model_snapshot={\"name\":\"startup.cfg\",\"modelCount\":1,\"models\":{\"spam_email\":{\"1.0\":{\"defaultVersion\":true,\"marName\":\"spam_email.mar\",\"minWorkers\":1,\"maxWorkers\":5,\"batchSize\":4,\"maxBatchDelay\":100,\"responseTimeout\":120}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e99e743-1903-4b7b-972b-06bfe995a12b",
   "metadata": {},
   "source": [
    "#### 1.4 Upload to MinIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49499526-d671-489a-8b9e-2522330c97f3",
   "metadata": {},
   "source": [
    "If you already have the minio storage, you can directly follow the next steps. If not, we also provide a standalone minio deployment guide on the kubernetes clusters.\n",
    "\n",
    "You can use the files from here [https://github.com/vmware/ml-ops-platform-for-vsphere/tree/main/website/content/en/docs/kubeflow-tutorial/lab4_minio_deploy], and apply in your clusters.\n",
    "\n",
    "`kubectl apply -f minio-standalone-pvc.yml` \n",
    "\n",
    "`kubectl apply -f minio-standalone-service.yml`\n",
    "\n",
    "`kubectl apply -f minio-standalone-deployment.yml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc43bf8",
   "metadata": {},
   "source": [
    "This step uploads `torchserve/model-store`, `torchserve/config` to MinIO buckets\n",
    "\n",
    "You need to find the MINIO\n",
    "- `endpoint_url`\n",
    "- `key_id`\n",
    "- `access_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "644fb1ea-3364-48a0-a312-535ceb9b7048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.8/site-packages (1.24.91)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.91 in /opt/conda/lib/python3.8/site-packages (from boto3) (1.27.91)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.91->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.91->boto3) (1.26.11)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.91->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e69a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "\n",
    "os.environ[\"AWS_ENDPOINT_URL\"] = \"http://10.117.233.16:9000\"\n",
    "os.environ[\"AWS_REGION\"] = \"us-east-1\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minioadmin\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin\"\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                    endpoint_url=os.getenv(\"AWS_ENDPOINT_URL\"),\n",
    "                    verify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b1b511d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current buckets in s3:\n",
      "[s3.Bucket(name='xujinheng-bucket')]\n"
     ]
    }
   ],
   "source": [
    "print(\"current buckets in s3:\")\n",
    "print(list(s3.buckets.all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6acc33f8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "bucket_name='spam-bucket'\n",
    "s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a1b2f6",
   "metadata": {},
   "source": [
    "Upload files to your bucket_name, and you can also specify `bucket_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb5c40e-808e-49cc-9db5-070fc2b51841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam_email/config/config.properties\n",
      "spam_email/model-store/spam_email.mar\n"
     ]
    }
   ],
   "source": [
    "curr_path = os.getcwd()\n",
    "base_path = os.path.join(curr_path, \"torchserve\")\n",
    "\n",
    "bucket_path = \"spam_email\"\n",
    "\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# upload\n",
    "bucket.upload_file(os.path.join(base_path, \"model-store\", \"spam_email.mar\"),\n",
    "                   os.path.join(bucket_path, \"model-store/spam_email.mar\"))\n",
    "bucket.upload_file(os.path.join(base_path, \"config\", \"config.properties\"), \n",
    "                   os.path.join(bucket_path, \"config/config.properties\"))\n",
    "\n",
    "# check files \n",
    "for obj in bucket.objects.filter(Prefix=bucket_path):\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3fe861-c578-4f37-9f55-7c00b9b28b82",
   "metadata": {},
   "source": [
    "## 2 KServe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fbbc31-87a5-43f3-b7c6-5254091b8783",
   "metadata": {},
   "source": [
    "#### 2.1 Create Minio service account && secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f14c8-dab6-499c-b16b-0d1aea473ad7",
   "metadata": {},
   "source": [
    "- You will also need to specify the `s3-endpoint`, `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` here\n",
    "- If you are using default user `user@exampe.com/12341234`, please also set a different name for all the <span style=\"color:red\">metadata: name</span> in the yaml file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257bbe98-3840-4993-aa97-0b8802b1baf1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/minio-s3-secret-user configured\n",
      "serviceaccount/minio-service-account-user configured\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat << EOF | kubectl apply -f -\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: minio-s3-secret-user\n",
    "  annotations:\n",
    "     serving.kserve.io/s3-endpoint: \"10.117.233.16:9000\" # replace with your s3 endpoint e.g minio-service.kubeflow:9000\n",
    "     serving.kserve.io/s3-usehttps: \"0\" # by default 1, if testing with minio you can set to 0\n",
    "     serving.kserve.io/s3-region: \"us-east-2\"\n",
    "     serving.kserve.io/s3-useanoncredential: \"false\" # omitting this is the same as false, if true will ignore provided credential and use anonymous credentials\n",
    "type: Opaque\n",
    "stringData: # use \"stringData\" for raw credential string or \"data\" for base64 encoded string\n",
    "  AWS_ACCESS_KEY_ID: minioadmin\n",
    "  AWS_SECRET_ACCESS_KEY: minioadmin\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  name: minio-service-account-user\n",
    "secrets:\n",
    "- name: minio-s3-secret-user\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5503d63-9294-4974-8c81-822fa790d5c5",
   "metadata": {},
   "source": [
    "#### 2.2 Create InferenceService from MinIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81556391",
   "metadata": {},
   "source": [
    "- Set `storageUri` to your `bucket_name/bucket_path`\n",
    "- You may also need to change `metadata: name` and `serviceAccountName` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bb67b2a-e446-46d3-9851-f12f51c49500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kserve.io/spam-email-serving created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat << EOF | kubectl apply -f -\n",
    "apiVersion: \"serving.kserve.io/v1beta1\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: \"spam-email-serving\"\n",
    "spec:\n",
    "  predictor:\n",
    "    serviceAccountName: minio-service-account-user\n",
    "    model:\n",
    "      modelFormat:\n",
    "        name: pytorch\n",
    "      storageUri: \"s3://spam-bucket/spam_email\"\n",
    "      resources:\n",
    "          requests:\n",
    "            cpu: 50m\n",
    "            memory: 200Mi\n",
    "          limits:\n",
    "            cpu: 100m\n",
    "            memory: 500Mi\n",
    "          # limits:\n",
    "          #   nvidia.com/gpu: \"1\"   # for inference service on GPU\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb8883",
   "metadata": {},
   "source": [
    "#### 2.3 Kubeflow UI\n",
    "\n",
    "Check model logs at [Kubeflow UI -> Models](/models/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01972d2-becc-45d9-8439-6de84d26caf7",
   "metadata": {},
   "source": [
    "## 3 Test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec065802",
   "metadata": {},
   "source": [
    "#### 3.1 Define a Test_bot for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "212a5487-b3a6-4765-96ef-704fd43c586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (0.70.13)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in /opt/conda/lib/python3.8/site-packages (from multiprocess) (0.3.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install multiprocess -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1fe8776-a5b2-4dd5-b364-0d29df632f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import multiprocess as mp\n",
    "\n",
    "class Test_bot():\n",
    "    def __init__(self, uri, model, host, session):\n",
    "        self.uri = uri\n",
    "        self.model = model\n",
    "        self.host = host\n",
    "        self.session = session\n",
    "        self.headers = {'Host': self.host, 'Content-Type': \"application/json\", 'Cookie': \"authservice_session=\" + self.session}\n",
    "        self.email = [\n",
    "        # features: shorter_text, body, business, html, money\n",
    "        \"[0, 0, 0, 0, 0] email longer than 500 character\" + \"a\" * 500,                                     # ham\n",
    "        \"[1, 0, 0, 0, 0] email shorter than 500 character\",                                                # ham\n",
    "        \"[1, 0, 1, 1, 1] email shorter than 500 character + business + html + money\",                      # spam\n",
    "        \"[0, 1, 0, 0, 1] email longer than 500 character + body\" + \"a\" * 500,                              # spam\n",
    "        \"[0, 1, 1, 1, 1] email longer than 500 character + body + business + html + money\" + \"a\" * 500,    # spam\n",
    "        \"[1, 1, 1, 1, 1] email shorter than 500 character body + business + html + money\",                 # spam\n",
    "        ]\n",
    "    \n",
    "    def update_uri(self, uri):\n",
    "        self.uri = uri\n",
    "        \n",
    "    def update_model(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def update_host(self, host):\n",
    "        self.host = host\n",
    "        self.update_headers()\n",
    "        \n",
    "    def update_session(self, session):\n",
    "        self.session = session\n",
    "        self.update_headers()\n",
    "        \n",
    "    def update_headers(self):\n",
    "        self.headers = {'Host': self.host, 'Content-Type': \"application/json\", 'Cookie': \"authservice_session=\" + self.session}\n",
    "        \n",
    "    def get_data(self, x):\n",
    "        if isinstance(x, str):\n",
    "            email = x\n",
    "        elif isinstance(x, int):\n",
    "            email = self.email[x % 6]\n",
    "        else:\n",
    "            email = self.email[0]\n",
    "        json_data = json.dumps({\n",
    "            \"instances\": [\n",
    "                email,\n",
    "            ]\n",
    "        })\n",
    "        return json_data\n",
    "        \n",
    "    def readiness(self):\n",
    "        uri = self.uri + '/v1/models/' + self.model\n",
    "        response = requests.get(uri, headers = self.headers, timeout=5)\n",
    "        return response.text\n",
    "\n",
    "    def predict(self, x=None):\n",
    "        uri = self.uri + '/v1/models/' + self.model + ':predict'\n",
    "        response = requests.post(uri, data=self.get_data(x), headers = self.headers, timeout=10)\n",
    "        return response.text\n",
    "    \n",
    "    def explain(self, x=None):\n",
    "        uri = self.uri + '/v1/models/' + self.model + ':explain'\n",
    "        response = requests.post(uri, data=self.get_data(x), headers = self.headers, timeout=10)\n",
    "        return response.text\n",
    "    \n",
    "    def concurrent_predict(self, num=10):\n",
    "        print(\"fire \" + str(num) + \" requests to \" + self.host)\n",
    "        with mp.Pool() as pool:\n",
    "            responses = pool.map(self.predict, range(num))\n",
    "        return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1311d0b7",
   "metadata": {},
   "source": [
    "#### 3.2 Determine host and session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7aadc6",
   "metadata": {},
   "source": [
    "Run the following cell to get `host`, which will be set to the headers in our request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfb136db-76ac-4a9b-81a2-d49529ec2474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam-email-serving.kubeflow-user-example-com.example.com\n"
     ]
    }
   ],
   "source": [
    "!kubectl get inferenceservice spam-email-serving -o jsonpath='{.status.url}' | cut -d \"/\" -f 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9709d26a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Use your web browser to login to Kubeflow, and get `Cookies: authservice_session` (Chrome: Developer Tools -> Applications -> Cookies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5079b4e7-ee8f-4388-a130-f5484d7bbf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"spam_email\", \"ready\": true}\n",
      "{\"predictions\": [{\"version\": \"2\", \"prediction\": \"ham\"}]}\n"
     ]
    }
   ],
   "source": [
    "               # replace it with the url you used to access Kubeflow\n",
    "bot = Test_bot(uri='http://10.117.233.8',\n",
    "               model='spam_email',\n",
    "               # replace it with what is printed above\n",
    "               host='spam-email-serving.kubeflow-user-example-com.example.com',\n",
    "               # replace it\n",
    "               session='MTY2NjE2MDYyMHxOd3dBTkZZelVqVkdOVkJIVUVGR1IweEVTbG95VVRZMU5WaEVXbE5GTlV0WlVrWk1WRk5FTkU5WVIxZFJRelpLVFZoWVVFOVdSa0U9fMj0VhQPme_rORhhdy0mtBJk-yGWdzibFfPMdU3TztbJ')\n",
    "\n",
    "print(bot.readiness())\n",
    "print(bot.predict(0))\n",
    "# We didn't implement model explainer, so this result will be 500: Internal Server Error\n",
    "# https://kserve.github.io/website/0.8/modelserving/explainer/explainer/\n",
    "# print(bot.explain(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e69e12-085d-49d8-ae31-aacda5a66d36",
   "metadata": {},
   "source": [
    "## 4 Autoscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc6513",
   "metadata": {},
   "source": [
    "- Knative Pod Autoscaler (KPA)\n",
    "  - Part of the Knative Serving core and enabled by default once Knative Serving is installed.\n",
    "  - Supports scale to zero functionality.\n",
    "  - Does not support CPU-based autoscaling.\n",
    "  \n",
    "- Horizontal Pod Autoscaler (HPA)\n",
    "  - Not part of the Knative Serving core, and must be enabled after Knative Serving installation.\n",
    "  - Does not support scale to zero functionality.\n",
    "  - Supports CPU-based autoscaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f7acb-3c77-4abf-ad9f-bdbc310b532e",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">If you use CPU-based autotscaling, ake sure HPA is installed before move on </span> (check by `kubectl get deploy autoscaler-hpa -n knative-serving`), will need to install it from https://github.com/knative/serving/releases/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19394e",
   "metadata": {},
   "source": [
    "Add autoscaling tag to the InferenceService and apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74b38359-7824-450f-bb89-f5f1252ab57b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kserve.io/spam-email-serving configured\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat << EOF | kubectl apply -f -\n",
    "apiVersion: serving.kserve.io/v1beta1\n",
    "kind: InferenceService\n",
    "metadata:\n",
    "  name: spam-email-serving\n",
    "  annotations:\n",
    "    autoscaling.knative.dev/class: hpa.autoscaling.knative.dev\n",
    "    # see available tags: https://knative.dev/docs/serving/autoscaling/autoscaling-targets/\n",
    "    autoscaling.knative.dev/max-scale: \"3\"\n",
    "    # HPA: specifies the CPU percentage target (default \"80\"). \n",
    "    # KPA: Target x requests in-flight per pod.\n",
    "    autoscaling.knative.dev/target: \"80\"  \n",
    "spec:\n",
    "  predictor:\n",
    "    pytorch:\n",
    "      # use uri as storage is also supported\n",
    "      storageUri: https://github.com/vmware/ml-ops-platform-for-vsphere/tree/main/website/content/en/docs/kubeflow-tutorial/lab4_files/v1.zip\n",
    "      resources:\n",
    "        requests:\n",
    "          cpu: 50m\n",
    "          memory: 200Mi\n",
    "        limits:\n",
    "          cpu: 200m\n",
    "          memory: 500Mi\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e561285",
   "metadata": {},
   "source": [
    "Check the number of pods. It takes a while before the one deployment get replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6916d61d-3521-4cc6-b461-7fbd19594e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS        RESTARTS   AGE\n",
      "bitfusion-notebook-01-0                                           2/2     Running       0          46d\n",
      "ml-pipeline-ui-artifact-7cd897c59f-kzlfs                          2/2     Running       0          49d\n",
      "ml-pipeline-visualizationserver-795f7db965-gzjsm                  2/2     Running       0          49d\n",
      "model-serving-test-0                                              2/2     Running       0          22h\n",
      "sklearn-iris-predictor-default-00001-deployment-5484f4d57-ld2fr   3/3     Running       0          18h\n",
      "spam-email-jhx-predictor-default-00001-deployment-6c857d65p2vs5   1/3     Terminating   0          171m\n",
      "spam-email-serving-predictor-default-00001-deployment-96949br62   3/3     Running       0          2m32s\n",
      "spam-email-serving-predictor-default-00002-deployment-6fc9r98xx   3/3     Running       0          37s\n",
      "spam-email-serving-predictor-default-00002-deployment-cdd4lz26s   1/3     Terminating   0          23m\n",
      "spam-email-serving-predictor-default-00003-deployment-5dc7s8nqf   1/3     Terminating   0          18m\n",
      "torchserve-06-predictor-default-00001-deployment-5577f6f9bdxzzm   1/3     Terminating   0          4h49m\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4770bcd",
   "metadata": {},
   "source": [
    "Adjust num of concurrent predict requests, fire it, let the the number of pods scale up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e24f94e9-1d96-4a8d-a11f-79c60dc02cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire 1000 requests to spam-email-serving.kubeflow-user-example-com.example.com\n"
     ]
    }
   ],
   "source": [
    "responses = bot.concurrent_predict(num=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb241b7f",
   "metadata": {},
   "source": [
    "Check the number of pods again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df7688b5-5766-4e91-8c65-c041a2a434be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS        RESTARTS   AGE\n",
      "bitfusion-notebook-01-0                                           2/2     Running       0          46d\n",
      "ml-pipeline-ui-artifact-7cd897c59f-kzlfs                          2/2     Running       0          49d\n",
      "ml-pipeline-visualizationserver-795f7db965-gzjsm                  2/2     Running       0          49d\n",
      "model-serving-test-0                                              2/2     Running       0          22h\n",
      "sklearn-iris-predictor-default-00001-deployment-5484f4d57-ld2fr   3/3     Running       0          18h\n",
      "spam-email-serving-predictor-default-00001-deployment-96949br62   1/3     Terminating   0          3m55s\n",
      "spam-email-serving-predictor-default-00002-deployment-6fc9ghcv7   2/3     Running       0          15s\n",
      "spam-email-serving-predictor-default-00002-deployment-6fc9jjlnt   2/3     Running       0          12s\n",
      "spam-email-serving-predictor-default-00002-deployment-6fc9pz29r   2/3     Running       0          12s\n",
      "spam-email-serving-predictor-default-00002-deployment-6fc9r98xx   3/3     Running       0          2m\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82613c62-5fbd-4f46-b239-3eb171769c5f",
   "metadata": {},
   "source": [
    "## 5 Canary Rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cddbd6f6-8bc0-4741-a7d8-e8f92459f2e0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kserve.io/spam-email-serving configured\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat << EOF | kubectl apply -f -\n",
    "apiVersion: serving.kserve.io/v1beta1\n",
    "kind: InferenceService\n",
    "metadata:\n",
    "  name: spam-email-serving\n",
    "  annotations:\n",
    "    autoscaling.knative.dev/class: hpa.autoscaling.knative.dev\n",
    "    autoscaling.knative.dev/target: \"80\"\n",
    "    serving.kserve.io/enable-tag-routing: \"true\"\n",
    "spec:\n",
    "  predictor:\n",
    "    canaryTrafficPercent: 20\n",
    "    pytorch:\n",
    "      storageUri: https://github.com/vmware/ml-ops-platform-for-vsphere/tree/main/website/content/en/docs/kubeflow-tutorial/lab4_files/v2.zip\n",
    "      resources:\n",
    "        requests:\n",
    "          cpu: 50m\n",
    "          memory: 200Mi\n",
    "        limits:\n",
    "          cpu: 200m\n",
    "          memory: 500Mi\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2cbbb00-6c56-401f-b35a-e9f5a4575da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                         CONFIG NAME                            K8S SERVICE NAME   GENERATION   READY   REASON   ACTUAL REPLICAS   DESIRED REPLICAS\n",
      "spam-email-serving-predictor-default-00001   spam-email-serving-predictor-default                      1            True             0                 1\n",
      "spam-email-serving-predictor-default-00002   spam-email-serving-predictor-default                      2            True             4                 4\n",
      "spam-email-serving-predictor-default-00003   spam-email-serving-predictor-default                      3            True             1                 0\n"
     ]
    }
   ],
   "source": [
    "!kubectl get revisions -l serving.kserve.io/inferenceservice=spam-email-serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d5a0b0b-bd6e-4d19-969e-6571e315dfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS        RESTARTS   AGE\n",
      "spam-email-serving-predictor-default-00001-deployment-96949br62   1/3     Terminating   0          4m50s\n",
      "spam-email-serving-predictor-default-00001-deployment-9694gwd89   2/3     Running       0          33s\n",
      "spam-email-serving-predictor-default-00002-deployment-6fc9ghcv7   3/3     Running       0          70s\n",
      "spam-email-serving-predictor-default-00002-deployment-6fc9jjlnt   3/3     Running       0          67s\n",
      "spam-email-serving-predictor-default-00002-deployment-6fc9pz29r   3/3     Running       0          67s\n",
      "spam-email-serving-predictor-default-00002-deployment-6fc9r98xx   3/3     Running       0          2m55s\n",
      "spam-email-serving-predictor-default-00003-deployment-fb5drzk4m   3/3     Running       0          30s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -l serving.kserve.io/inferenceservice=spam-email-serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885aa007-54f7-495a-a324-d0ffd631958a",
   "metadata": {},
   "source": [
    "check traffic status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b787eb9-f2f8-49dc-8918-c2756ecb1d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 URL                                                               READY   PREV   LATEST   PREVROLLEDOUTREVISION                        LATESTREADYREVISION                          AGE\n",
      "spam-email-serving   http://spam-email-serving.kubeflow-user-example-com.example.com   True    80     20       spam-email-serving-predictor-default-00002   spam-email-serving-predictor-default-00003   5m5s\n",
      "apiVersion: serving.kserve.io/v1beta1\n",
      "kind: InferenceService\n",
      "metadata:\n",
      "  annotations:\n",
      "    autoscaling.knative.dev/class: hpa.autoscaling.knative.dev\n",
      "    autoscaling.knative.dev/target: \"80\"\n",
      "    kubectl.kubernetes.io/last-applied-configuration: |\n",
      "      {\"apiVersion\":\"serving.kserve.io/v1beta1\",\"kind\":\"InferenceService\",\"metadata\":{\"annotations\":{\"autoscaling.knative.dev/class\":\"hpa.autoscaling.knative.dev\",\"autoscaling.knative.dev/target\":\"80\",\"serving.kserve.io/enable-tag-routing\":\"true\"},\"name\":\"spam-email-serving\",\"namespace\":\"kubeflow-user-example-com\"},\"spec\":{\"predictor\":{\"canaryTrafficPercent\":20,\"pytorch\":{\"resources\":{\"limits\":{\"cpu\":\"200m\",\"memory\":\"500Mi\"},\"requests\":{\"cpu\":\"50m\",\"memory\":\"200Mi\"}},\"storageUri\":\"https://www.ocf.berkeley.edu/~jhx/S3-Mock-Server/buckets/xujinheng-bucket/spam_email/v2.zip\"}}}}\n",
      "    serving.kserve.io/enable-tag-routing: \"true\"\n",
      "  creationTimestamp: \"2022-10-19T06:29:53Z\"\n",
      "  finalizers:\n",
      "  - inferenceservice.finalizers\n",
      "  generation: 3\n",
      "  labels:\n",
      "    serviceEnvelope: kserve\n",
      "  name: spam-email-serving\n",
      "  namespace: kubeflow-user-example-com\n",
      "  resourceVersion: \"32513754\"\n",
      "  uid: e960e094-6972-412b-a484-38a487c04e9f\n",
      "spec:\n",
      "  predictor:\n",
      "    canaryTrafficPercent: 20\n",
      "    model:\n",
      "      modelFormat:\n",
      "        name: pytorch\n",
      "      name: \"\"\n",
      "      resources:\n",
      "        limits:\n",
      "          cpu: 200m\n",
      "          memory: 500Mi\n",
      "        requests:\n",
      "          cpu: 50m\n",
      "          memory: 200Mi\n",
      "      runtime: kserve-torchserve\n",
      "      storageUri: https://www.ocf.berkeley.edu/~jhx/S3-Mock-Server/buckets/xujinheng-bucket/spam_email/v2.zip\n",
      "status:\n",
      "  address:\n",
      "    url: http://spam-email-serving.kubeflow-user-example-com.svc.cluster.local/v2/models/spam-email-serving/infer\n",
      "  components:\n",
      "    predictor:\n",
      "      address:\n",
      "        url: http://spam-email-serving-predictor-default.kubeflow-user-example-com.svc.cluster.local\n",
      "      latestCreatedRevision: spam-email-serving-predictor-default-00003\n",
      "      latestReadyRevision: spam-email-serving-predictor-default-00003\n",
      "      latestRolledoutRevision: spam-email-serving-predictor-default-00002\n",
      "      previousRolledoutRevision: spam-email-serving-predictor-default-00001\n",
      "      traffic:\n",
      "      - latestRevision: true\n",
      "        percent: 20\n",
      "        revisionName: spam-email-serving-predictor-default-00003\n",
      "        tag: latest\n",
      "        url: http://latest-spam-email-serving-predictor-default.kubeflow-user-example-com.example.com\n",
      "      - latestRevision: false\n",
      "        percent: 80\n",
      "        revisionName: spam-email-serving-predictor-default-00002\n",
      "        tag: prev\n",
      "        url: http://prev-spam-email-serving-predictor-default.kubeflow-user-example-com.example.com\n",
      "      url: http://spam-email-serving-predictor-default.kubeflow-user-example-com.example.com\n",
      "  conditions:\n",
      "  - lastTransitionTime: \"2022-10-19T06:34:43Z\"\n",
      "    status: \"True\"\n",
      "    type: IngressReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:34:43Z\"\n",
      "    severity: Info\n",
      "    status: \"True\"\n",
      "    type: PredictorConfigurationReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:34:43Z\"\n",
      "    status: \"True\"\n",
      "    type: PredictorReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:34:43Z\"\n",
      "    severity: Info\n",
      "    status: \"True\"\n",
      "    type: PredictorRouteReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:34:43Z\"\n",
      "    status: \"True\"\n",
      "    type: Ready\n",
      "  url: http://spam-email-serving.kubeflow-user-example-com.example.com\n"
     ]
    }
   ],
   "source": [
    "!kubectl get isvc spam-email-serving\n",
    "!kubectl get isvc spam-email-serving -o yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fdf4e1",
   "metadata": {},
   "source": [
    "Fire concurrent predict request the model, you should see most of the responses have `version : 1`, but `20%` have `version: 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "790dd483-c7a4-4d80-8477-2f2b7174b6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire 100 requests to spam-email-serving.kubeflow-user-example-com.example.com\n",
      "Number of Version 1:  59\n",
      "Number of Version 2:  14\n",
      "['{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"spam\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"spam\"}]}', '{\"predictions\": [{\"version\": \"2\", \"prediction\": \"ham\"}]}', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}', '<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>', '{\"predictions\": [{\"version\": \"1\", \"prediction\": \"ham\"}]}']\n"
     ]
    }
   ],
   "source": [
    "responses = bot.concurrent_predict(100)\n",
    "print(\"Number of Version 1: \", len(list(filter(lambda x: '\"version\": \"1\"' in x, responses))))\n",
    "print(\"Number of Version 2: \", len(list(filter(lambda x: '\"version\": \"2\"' in x, responses))))\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd76557",
   "metadata": {},
   "source": [
    "Replace host address with the url you print in the cell above, but use the url starts with `prev-spam-email`\n",
    "\n",
    "You should see all responses have `version: 1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f70cd08-d76b-4085-ad91-311f083e587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire 20 requests to prev-spam-email-serving-predictor-default.user.example.com\n",
      "Number of Version 1:  0\n",
      "Number of Version 2:  0\n",
      "['<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n', '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /v1/models/spam_email:predict</pre>\\n</body>\\n</html>\\n']\n"
     ]
    }
   ],
   "source": [
    "bot.update_host('prev-spam-email-serving-predictor-default.user.example.com')\n",
    "responses = bot.concurrent_predict(20)\n",
    "print(\"Number of Version 1: \", len(list(filter(lambda x: '\"version\": \"1\"' in x, responses))))\n",
    "print(\"Number of Version 2: \", len(list(filter(lambda x: '\"version\": \"2\"' in x, responses))))\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0672e48",
   "metadata": {},
   "source": [
    "Adjust traffic of new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f26429f-928b-4b00-ab51-15989224c6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kserve.io/spam-email-serving patched\n"
     ]
    }
   ],
   "source": [
    "!kubectl patch isvc spam-email-serving --type='json' -p '[{\"op\": \"replace\", \"path\": \"/spec/predictor/canaryTrafficPercent\", \"value\": 50}]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8696925-925d-4782-a113-82c572b18008",
   "metadata": {},
   "source": [
    "Set traffic of new model to 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4301c2b-c2b8-49a6-aee4-23251d3821f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kserve.io/spam-email-serving patched\n",
      "NAME                 URL                                                               READY   PREV   LATEST   PREVROLLEDOUTREVISION   LATESTREADYREVISION                          AGE\n",
      "spam-email-serving   http://spam-email-serving.kubeflow-user-example-com.example.com   True           100                              spam-email-serving-predictor-default-00003   5m41s\n",
      "apiVersion: serving.kserve.io/v1beta1\n",
      "kind: InferenceService\n",
      "metadata:\n",
      "  annotations:\n",
      "    autoscaling.knative.dev/class: hpa.autoscaling.knative.dev\n",
      "    autoscaling.knative.dev/target: \"80\"\n",
      "    kubectl.kubernetes.io/last-applied-configuration: |\n",
      "      {\"apiVersion\":\"serving.kserve.io/v1beta1\",\"kind\":\"InferenceService\",\"metadata\":{\"annotations\":{\"autoscaling.knative.dev/class\":\"hpa.autoscaling.knative.dev\",\"autoscaling.knative.dev/target\":\"80\",\"serving.kserve.io/enable-tag-routing\":\"true\"},\"name\":\"spam-email-serving\",\"namespace\":\"kubeflow-user-example-com\"},\"spec\":{\"predictor\":{\"canaryTrafficPercent\":20,\"pytorch\":{\"resources\":{\"limits\":{\"cpu\":\"200m\",\"memory\":\"500Mi\"},\"requests\":{\"cpu\":\"50m\",\"memory\":\"200Mi\"}},\"storageUri\":\"https://www.ocf.berkeley.edu/~jhx/S3-Mock-Server/buckets/xujinheng-bucket/spam_email/v2.zip\"}}}}\n",
      "    serving.kserve.io/enable-tag-routing: \"true\"\n",
      "  creationTimestamp: \"2022-10-19T06:29:53Z\"\n",
      "  finalizers:\n",
      "  - inferenceservice.finalizers\n",
      "  generation: 5\n",
      "  labels:\n",
      "    serviceEnvelope: kserve\n",
      "  name: spam-email-serving\n",
      "  namespace: kubeflow-user-example-com\n",
      "  resourceVersion: \"32514213\"\n",
      "  uid: e960e094-6972-412b-a484-38a487c04e9f\n",
      "spec:\n",
      "  predictor:\n",
      "    canaryTrafficPercent: 100\n",
      "    model:\n",
      "      modelFormat:\n",
      "        name: pytorch\n",
      "      name: \"\"\n",
      "      resources:\n",
      "        limits:\n",
      "          cpu: 200m\n",
      "          memory: 500Mi\n",
      "        requests:\n",
      "          cpu: 50m\n",
      "          memory: 200Mi\n",
      "      runtime: kserve-torchserve\n",
      "      storageUri: https://www.ocf.berkeley.edu/~jhx/S3-Mock-Server/buckets/xujinheng-bucket/spam_email/v2.zip\n",
      "status:\n",
      "  address:\n",
      "    url: http://spam-email-serving.kubeflow-user-example-com.svc.cluster.local/v2/models/spam-email-serving/infer\n",
      "  components:\n",
      "    predictor:\n",
      "      address:\n",
      "        url: http://spam-email-serving-predictor-default.kubeflow-user-example-com.svc.cluster.local\n",
      "      latestCreatedRevision: spam-email-serving-predictor-default-00003\n",
      "      latestReadyRevision: spam-email-serving-predictor-default-00003\n",
      "      latestRolledoutRevision: spam-email-serving-predictor-default-00003\n",
      "      previousRolledoutRevision: spam-email-serving-predictor-default-00002\n",
      "      traffic:\n",
      "      - latestRevision: true\n",
      "        percent: 100\n",
      "        revisionName: spam-email-serving-predictor-default-00003\n",
      "        tag: latest\n",
      "        url: http://latest-spam-email-serving-predictor-default.kubeflow-user-example-com.example.com\n",
      "      url: http://spam-email-serving-predictor-default.kubeflow-user-example-com.example.com\n",
      "  conditions:\n",
      "  - lastTransitionTime: \"2022-10-19T06:35:34Z\"\n",
      "    status: \"True\"\n",
      "    type: IngressReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:34:43Z\"\n",
      "    severity: Info\n",
      "    status: \"True\"\n",
      "    type: PredictorConfigurationReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:35:34Z\"\n",
      "    status: \"True\"\n",
      "    type: PredictorReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:35:34Z\"\n",
      "    severity: Info\n",
      "    status: \"True\"\n",
      "    type: PredictorRouteReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:35:34Z\"\n",
      "    status: \"True\"\n",
      "    type: Ready\n",
      "  url: http://spam-email-serving.kubeflow-user-example-com.example.com\n"
     ]
    }
   ],
   "source": [
    "!kubectl patch isvc spam-email-serving --type='json' -p '[{\"op\": \"replace\", \"path\": \"/spec/predictor/canaryTrafficPercent\", \"value\": 100}]'\n",
    "!kubectl get isvc spam-email-serving\n",
    "!kubectl get isvc spam-email-serving -o yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4725719-0722-4d19-894f-a6620dbf0938",
   "metadata": {},
   "source": [
    "rollback the new model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d965d89-c1b4-4de3-9c3e-5d0e74352520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kserve.io/spam-email-serving patched\n",
      "NAME                 URL                                                               READY   PREV   LATEST   PREVROLLEDOUTREVISION                        LATESTREADYREVISION                          AGE\n",
      "spam-email-serving   http://spam-email-serving.kubeflow-user-example-com.example.com   True    100    0        spam-email-serving-predictor-default-00002   spam-email-serving-predictor-default-00003   5m52s\n",
      "apiVersion: serving.kserve.io/v1beta1\n",
      "kind: InferenceService\n",
      "metadata:\n",
      "  annotations:\n",
      "    autoscaling.knative.dev/class: hpa.autoscaling.knative.dev\n",
      "    autoscaling.knative.dev/target: \"80\"\n",
      "    kubectl.kubernetes.io/last-applied-configuration: |\n",
      "      {\"apiVersion\":\"serving.kserve.io/v1beta1\",\"kind\":\"InferenceService\",\"metadata\":{\"annotations\":{\"autoscaling.knative.dev/class\":\"hpa.autoscaling.knative.dev\",\"autoscaling.knative.dev/target\":\"80\",\"serving.kserve.io/enable-tag-routing\":\"true\"},\"name\":\"spam-email-serving\",\"namespace\":\"kubeflow-user-example-com\"},\"spec\":{\"predictor\":{\"canaryTrafficPercent\":20,\"pytorch\":{\"resources\":{\"limits\":{\"cpu\":\"200m\",\"memory\":\"500Mi\"},\"requests\":{\"cpu\":\"50m\",\"memory\":\"200Mi\"}},\"storageUri\":\"https://www.ocf.berkeley.edu/~jhx/S3-Mock-Server/buckets/xujinheng-bucket/spam_email/v2.zip\"}}}}\n",
      "    serving.kserve.io/enable-tag-routing: \"true\"\n",
      "  creationTimestamp: \"2022-10-19T06:29:53Z\"\n",
      "  finalizers:\n",
      "  - inferenceservice.finalizers\n",
      "  generation: 6\n",
      "  labels:\n",
      "    serviceEnvelope: kserve\n",
      "  name: spam-email-serving\n",
      "  namespace: kubeflow-user-example-com\n",
      "  resourceVersion: \"32514355\"\n",
      "  uid: e960e094-6972-412b-a484-38a487c04e9f\n",
      "spec:\n",
      "  predictor:\n",
      "    canaryTrafficPercent: 0\n",
      "    model:\n",
      "      modelFormat:\n",
      "        name: pytorch\n",
      "      name: \"\"\n",
      "      resources:\n",
      "        limits:\n",
      "          cpu: 200m\n",
      "          memory: 500Mi\n",
      "        requests:\n",
      "          cpu: 50m\n",
      "          memory: 200Mi\n",
      "      runtime: kserve-torchserve\n",
      "      storageUri: https://www.ocf.berkeley.edu/~jhx/S3-Mock-Server/buckets/xujinheng-bucket/spam_email/v2.zip\n",
      "status:\n",
      "  address:\n",
      "    url: http://spam-email-serving.kubeflow-user-example-com.svc.cluster.local/v2/models/spam-email-serving/infer\n",
      "  components:\n",
      "    predictor:\n",
      "      address:\n",
      "        url: http://spam-email-serving-predictor-default.kubeflow-user-example-com.svc.cluster.local\n",
      "      latestCreatedRevision: spam-email-serving-predictor-default-00003\n",
      "      latestReadyRevision: spam-email-serving-predictor-default-00003\n",
      "      latestRolledoutRevision: spam-email-serving-predictor-default-00002\n",
      "      previousRolledoutRevision: spam-email-serving-predictor-default-00002\n",
      "      traffic:\n",
      "      - latestRevision: true\n",
      "        percent: 0\n",
      "        revisionName: spam-email-serving-predictor-default-00003\n",
      "        tag: latest\n",
      "        url: http://latest-spam-email-serving-predictor-default.kubeflow-user-example-com.example.com\n",
      "      - latestRevision: false\n",
      "        percent: 100\n",
      "        revisionName: spam-email-serving-predictor-default-00002\n",
      "        tag: prev\n",
      "        url: http://prev-spam-email-serving-predictor-default.kubeflow-user-example-com.example.com\n",
      "      url: http://spam-email-serving-predictor-default.kubeflow-user-example-com.example.com\n",
      "  conditions:\n",
      "  - lastTransitionTime: \"2022-10-19T06:35:45Z\"\n",
      "    status: \"True\"\n",
      "    type: IngressReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:34:43Z\"\n",
      "    severity: Info\n",
      "    status: \"True\"\n",
      "    type: PredictorConfigurationReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:35:45Z\"\n",
      "    status: \"True\"\n",
      "    type: PredictorReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:35:45Z\"\n",
      "    severity: Info\n",
      "    status: \"True\"\n",
      "    type: PredictorRouteReady\n",
      "  - lastTransitionTime: \"2022-10-19T06:35:45Z\"\n",
      "    status: \"True\"\n",
      "    type: Ready\n",
      "  url: http://spam-email-serving.kubeflow-user-example-com.example.com\n"
     ]
    }
   ],
   "source": [
    "!kubectl patch isvc spam-email-serving --type='json' -p '[{\"op\": \"replace\", \"path\": \"/spec/predictor/canaryTrafficPercent\", \"value\": 0}]'\n",
    "!kubectl get isvc spam-email-serving\n",
    "!kubectl get isvc spam-email-serving -o yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0704f",
   "metadata": {},
   "source": [
    "## 6 More\n",
    "Explore the Kserve 0.8 docs here https://kserve.github.io/website/0.8/modelserving/control_plane/\n",
    "\n",
    "- Multi Model Serving\n",
    "- Transformers\n",
    "- Model Explainability\n",
    "- Model Monitoring\n",
    "- Payload Logging\n",
    "- etc.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d8fcee15318561c421fd029289997adde12df0a6deb462b29cf55fa6694a6d5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
