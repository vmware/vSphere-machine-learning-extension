{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9adc65d-da6f-4596-95b0-e9f12377ef7c",
   "metadata": {},
   "source": [
    "# ModelScope\n",
    "\n",
    "Text to Video Synthesis\n",
    "\n",
    "This notebook is adapted from https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb2ed0c-d737-45ba-96f6-5dcc5981845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY'] = 'http://proxy.vmware.com:3128'\n",
    "os.environ['HTTPS_PROXY'] = 'http://proxy.vmware.com:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2166d7a6-902e-4a14-a361-c896af14d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting modelscope==1.4.2\n",
      "  Downloading modelscope-1.4.2-py3-none-any.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting open_clip_torch\n",
      "  Obtaining dependency information for open_clip_torch from https://files.pythonhosted.org/packages/70/b9/a9f2c37f998c20be57fed0128934f4a311c6596c1f6b9c2fe358b26125bc/open_clip_torch-2.20.0-py3-none-any.whl.metadata\n",
      "  Downloading open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning\n",
      "  Obtaining dependency information for pytorch-lightning from https://files.pythonhosted.org/packages/fa/c7/18aca7e74b6c4bb99ceb76a7742716543f040834b8440acad4afaf528e46/pytorch_lightning-2.0.9-py3-none-any.whl.metadata\n",
      "  Downloading pytorch_lightning-2.0.9-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting opencv-python-headless==4.5.3.56\n",
      "  Downloading opencv_python_headless-4.5.3.56-cp39-cp39-manylinux2014_x86_64.whl (37.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.1/37.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchtext==0.8.1\n",
      "  Downloading torchtext-0.8.1-cp39-cp39-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting addict (from modelscope==1.4.2)\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.9/site-packages (from modelscope==1.4.2) (23.1.0)\n",
      "Collecting datasets<=2.8.0,>=2.7.0 (from modelscope==1.4.2)\n",
      "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting einops (from modelscope==1.4.2)\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m340.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock>=3.3.0 in /opt/conda/lib/python3.9/site-packages (from modelscope==1.4.2) (3.12.2)\n",
      "Collecting gast>=0.2.2 (from modelscope==1.4.2)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting jsonplus (from modelscope==1.4.2)\n",
      "  Downloading jsonplus-0.8.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting numpy<1.24.0 (from modelscope==1.4.2)\n",
      "  Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting oss2 (from modelscope==1.4.2)\n",
      "  Downloading oss2-2.18.1.tar.gz (274 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.3/274.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from modelscope==1.4.2) (10.0.0)\n",
      "Collecting pyarrow!=9.0.0,>=6.0.0 (from modelscope==1.4.2)\n",
      "  Obtaining dependency information for pyarrow!=9.0.0,>=6.0.0 from https://files.pythonhosted.org/packages/49/db/0a40d2a5b2382c77536479894ce2900e5f4c40251681a72d397ba6430f8d/pyarrow-13.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading pyarrow-13.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from modelscope==1.4.2) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from modelscope==1.4.2) (2.31.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from modelscope==1.4.2) (1.11.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from modelscope==1.4.2) (68.0.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.9/site-packages (from modelscope==1.4.2) (4.65.0)\n",
      "Collecting yapf (from modelscope==1.4.2)\n",
      "  Obtaining dependency information for yapf from https://files.pythonhosted.org/packages/23/75/c374517c09e31bf22d3b3f156d73e0f38d08e29b2afdd607cef5f1e10aa9/yapf-0.40.1-py3-none-any.whl.metadata\n",
      "  Downloading yapf-0.40.1-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting torch==1.7.1 (from torchtext==0.8.1)\n",
      "  Downloading torch-1.7.1-cp39-cp39-manylinux1_x86_64.whl (776.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.8/776.8 MB\u001b[0m \u001b[31m539.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch==1.7.1->torchtext==0.8.1) (4.7.1)\n",
      "INFO: pip is looking at multiple versions of open-clip-torch to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting open_clip_torch\n",
      "  Downloading open_clip_torch-2.19.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.18.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.17.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.17.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.16.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.16.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.16.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hINFO: pip is still looking at multiple versions of open-clip-torch to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading open_clip_torch-2.15.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.14.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m650.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.13.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.12.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.11.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading open_clip_torch-2.11.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.10.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.10.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.9.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.9.2-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.9.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.8.2-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.8.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.8.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.7.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.6.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.5.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.4.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.4.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.3.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.3.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.2.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.0.2-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Downloading open_clip_torch-2.0.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-2.0.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-1.3.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-1.2.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Downloading open_clip_torch-1.2.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-1.1.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-1.0.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-0.2.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading open_clip_torch-0.2.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h\u001b[31mERROR: Cannot install open-clip-torch==0.2.0, open-clip-torch==0.2.1, open-clip-torch==1.0.1, open-clip-torch==1.1.1, open-clip-torch==1.2.0, open-clip-torch==1.2.1, open-clip-torch==1.3.0, open-clip-torch==2.0.0, open-clip-torch==2.0.1, open-clip-torch==2.0.2, open-clip-torch==2.10.0, open-clip-torch==2.10.1, open-clip-torch==2.11.0, open-clip-torch==2.11.1, open-clip-torch==2.12.0, open-clip-torch==2.13.0, open-clip-torch==2.14.0, open-clip-torch==2.15.0, open-clip-torch==2.16.0, open-clip-torch==2.16.1, open-clip-torch==2.16.2, open-clip-torch==2.17.1, open-clip-torch==2.17.2, open-clip-torch==2.18.0, open-clip-torch==2.19.0, open-clip-torch==2.2.0, open-clip-torch==2.20.0, open-clip-torch==2.3.0, open-clip-torch==2.3.1, open-clip-torch==2.4.0, open-clip-torch==2.4.1, open-clip-torch==2.5.0, open-clip-torch==2.6.1, open-clip-torch==2.7.0, open-clip-torch==2.8.0, open-clip-torch==2.8.1, open-clip-torch==2.8.2, open-clip-torch==2.9.1, open-clip-torch==2.9.2, open-clip-torch==2.9.3 and torchtext==0.8.1 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.20.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.19.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.18.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.17.2 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.17.1 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.16.2 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.16.1 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.16.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.15.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.14.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.13.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.12.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.11.1 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.11.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.10.1 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.10.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.9.3 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.9.2 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.9.1 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.8.2 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.8.1 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.8.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.7.0 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.6.1 depends on torch>=1.9.0\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.5.0 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.4.1 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.4.0 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.3.1 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.3.0 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.2.0 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.0.2 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.0.1 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 2.0.0 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 1.3.0 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 1.2.1 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 1.2.0 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 1.1.1 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 1.0.1 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 0.2.1 depends on torch>=1.9\n",
      "    torchtext 0.8.1 depends on torch==1.7.1\n",
      "    open-clip-torch 0.2.0 depends on torch>=1.9\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install modelscope==1.4.2 open_clip_torch pytorch-lightning opencv-python-headless==4.5.3.56 torchtext==0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf059ee-c6ce-4d65-9a8b-6162a9cc1381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.10.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp39-cp39-linux_x86_64.whl (2137.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 GB\u001b[0m \u001b[31m93.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0mm0:06\u001b[0mmm\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch==1.10.0+cu111) (4.7.1)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1+cu117\n",
      "    Uninstalling torch-1.13.1+cu117:\n",
      "      Successfully uninstalled torch-1.13.1+cu117\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 0.13.1+rocm5.2 requires torch==1.13.1, but you have torch 1.10.0+cu111 which is incompatible.\n",
      "torchvision 0.14.1+cu117 requires torch==1.13.1, but you have torch 1.10.0+cu111 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.10.0+cu111\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747f0605-dd2a-42d9-8ac1-269d61213ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/numpy/lib/scimath.py:46: RuntimeWarning: divide by zero encountered in log\n",
      "  _ln2 = nx.log(2.0)\n",
      "2023-09-17 04:33:24,540 - modelscope - INFO - PyTorch version 1.10.0+cu111 Found.\n",
      "2023-09-17 04:33:24,547 - modelscope - INFO - Loading ast index from /home/jovyan/.cache/modelscope/ast_indexer\n",
      "2023-09-17 04:33:24,666 - modelscope - INFO - Loading done! Current index file version is 1.4.2, with md5 0f971900167bc85a19644944d0dfee0b and a total number of 842 components indexed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'tensorflow'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2814743910ee4577b12d7ab9e11df3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 04:33:36,071 - modelscope - INFO - initiate model from weights\n",
      "2023-09-17 04:33:36,077 - modelscope - INFO - initiate model from location weights.\n",
      "2023-09-17 04:33:36,102 - modelscope - INFO - initialize model from weights\n",
      "2023-09-17 04:37:27,784 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "WARNING:modelscope:No preprocessor field found in cfg.\n",
      "2023-09-17 04:37:27,808 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "WARNING:modelscope:No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-09-17 04:37:27,812 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'weights'}. trying to build by task and model information.\n",
      "WARNING:modelscope:Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'weights'}. trying to build by task and model information.\n",
      "2023-09-17 04:37:27,814 - modelscope - WARNING - No preprocessor key ('latent-text-to-video-synthesis', 'text-to-video-synthesis') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "WARNING:modelscope:No preprocessor key ('latent-text-to-video-synthesis', 'text-to-video-synthesis') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2023-09-17 04:37:27,824 - modelscope - WARNING - task text-to-video-synthesis input definition is missing\n",
      "WARNING:modelscope:task text-to-video-synthesis input definition is missing\n",
      "2023-09-17 04:37:54,442 - modelscope - WARNING - task text-to-video-synthesis output keys are missing\n",
      "WARNING:modelscope:task text-to-video-synthesis output keys are missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_video_path: /tmp/tmpk6oigt1o.mp4\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.outputs import OutputKeys\n",
    "import pathlib\n",
    "\n",
    "model_dir = pathlib.Path('weights')\n",
    "snapshot_download('damo-vilab/modelscope-damo-text-to-video-synthesis',\n",
    "                   repo_type='model', local_dir=model_dir)\n",
    "\n",
    "pipe = pipeline('text-to-video-synthesis', model_dir.as_posix())\n",
    "test_text = {\n",
    "        'text': 'A panda eating bamboo on a rock.',\n",
    "    }\n",
    "output_video_path = pipe(test_text,)[OutputKeys.OUTPUT_VIDEO]\n",
    "print('output_video_path:', output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ebed9b-3452-40d9-8b18-687fd3538e92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
