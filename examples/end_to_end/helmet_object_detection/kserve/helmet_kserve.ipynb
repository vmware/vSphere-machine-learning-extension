{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5610b8-6dce-41a9-8ab9-95cad9296bb5",
   "metadata": {},
   "source": [
    "## 1 PyTorch Serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6545f4c-5e2d-48a6-88d0-4272ab9bf33c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Instructions\n",
    "\n",
    "```\n",
    "                                         1.2 Create an archive\n",
    "\n",
    "                                       ┌──────────────────────┐\n",
    "                                       │                      │\n",
    "                                       │   Torchserve Model   │\n",
    "                                       │       Archive        │\n",
    "                                       │                      │\n",
    "                                       │   ┌──────────────┐   │   ┌──────────────┐\n",
    "                                       │   │              │   │   │              │              1.3\n",
    " 1.1.1 custom model checkpoint ────────┼─► ├torchscript.pt┤   │   │  Torchserve  │              # workers\n",
    "                                       │   │              │   │   │              │ ◄──────────  # batchsize\n",
    "                                       │   └──────────────┘   │   │    config    │              max batch delay\n",
    "                                       │                      │   │              │              etc.\n",
    "        preprocess  code               │   ┌──────────────┐   │   └──────┬───────┘\n",
    "1.1.2      call model     ─────────────┼─► │  handler.py  │   │          │\n",
    "        postprocess code               │   └──────────────┘   │          │\n",
    "                                       │                      │          │\n",
    "                                       └──────────┬───────────┘          │\n",
    "                                                  │                      │\n",
    "                                                  │                      │\n",
    "                                                  │                      │\n",
    "                                       ┌──────────▼──────────────────────▼───────┐\n",
    "                                       │                                         │    1.4 Upload to storage\n",
    "                                       │   Storage   ( MinIO / S3 / Url / PVC )  │\n",
    "                                       │                                         │\n",
    "                                       └────────────────────┬────────────────────┘\n",
    "                                                            │\n",
    "                                       ┌────────────────────▼────────────────────┐\n",
    "                                       │                                         │    2 Define KServe Yaml\n",
    "                                       │             KServe Predictor            │\n",
    "                                       │                                         │    3 Do some basic testing\n",
    "                                       │             ( scaling pods )            │\n",
    "                                       │                                         │    4 Autoscaling\n",
    "                                       └─────────────────────────────────────────┘\n",
    "                                                                                      5 Canary Rollout\n",
    "     \n",
    " ```\n",
    " \n",
    "The lab mainly covers:\n",
    "- PyTorch Serve: package PyTorch model with custom preprocess/postprocess functions\n",
    "- MinIO storage usage\n",
    "- KServe: basic, autoscaling, canary rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b55886e",
   "metadata": {},
   "source": [
    "#### 1.1 Prepartion for Model Archiver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b721d1",
   "metadata": {},
   "source": [
    "Prepare 3 files:\n",
    "- helmet.pt: fine-tuning the model with your own data and save the parameters\n",
    "- helmet.torchscript.pt: a serialized file (.pt or .pth) should be a checkpoint in case of torchscript and state_dict in case of eager mode.\n",
    "- handler.py: codes for model initialization, pre-processing, post-processing, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ceb73",
   "metadata": {},
   "source": [
    "##### 1.1.1 helmet.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c0fec",
   "metadata": {},
   "source": [
    "All files in worker@10.186.48.212:/home/worker/helmet/yolov5_torchserve \n",
    "\n",
    "- Label, Process, Split your custom data\n",
    "\n",
    "`python prepare.py`\n",
    "\n",
    "- To fine-tune the model and save the checkpoint\n",
    "\n",
    "`python train`\n",
    "\n",
    "- Detect and Test\n",
    "\n",
    "`python detect.py --source 2.jpg --weights helmet.pt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0932219",
   "metadata": {},
   "source": [
    "##### 1.1.2 helmet.torchscript.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c186e",
   "metadata": {},
   "source": [
    "The helmet.torchscript.pt provide model architecture definition and checkpoints with torchserve.\n",
    "\n",
    "Export helmet.torchscript.pt\n",
    "\n",
    "`python export.py --weights helmet.pt --include torchscript`\n",
    "\n",
    "Learn more about eager-mode vs torchscript here:\n",
    "https://pytorch.org/tutorials/beginner/deploy_seq2seq_hybrid_frontend_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aca787f-7038-4e2d-a973-494ba27d5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p torchserve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f8e44",
   "metadata": {},
   "source": [
    "##### 1.1.3 Handler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6fad86",
   "metadata": {},
   "source": [
    "What can handler.py do? (https://pytorch.org/serve/custom_service.html)\n",
    "\n",
    "- Initialize the model instance\n",
    "- Pre-process input data before it is sent to the model for inference or Captum explanations\n",
    "- Customize how the model is invoked for inference or explanations\n",
    "- Post-process output from the model before sending back a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ddb6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting torchserve/torchserve_handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile torchserve/torchserve_handler.py\n",
    "# custom handler file\n",
    "\n",
    "\"\"\"Custom TorchServe model handler for YOLOv5 models.\n",
    "\"\"\"\n",
    "\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "import numpy as np\n",
    "import base64\n",
    "import torch\n",
    "import torchvision.transforms as tf\n",
    "import torchvision\n",
    "import io\n",
    "from PIL import Image\n",
    "import warnings\n",
    "\n",
    "# model_handler.py\n",
    "\n",
    "# BaseHandler:\n",
    "# https://github.com/pytorch/serve/blob/master/ts/torch_handler/base_handler.py\n",
    "\n",
    "\n",
    "class ModelHandler(BaseHandler):\n",
    "    \"\"\"\n",
    "    A custom model handler implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    img_size = 640\n",
    "    \"\"\"Image size (px). Images will be resized to this resolution before inference.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # call superclass initializer\n",
    "        super().__init__()\n",
    "        self._context = None\n",
    "        self.initialized = False\n",
    "        self.batch_size = 1\n",
    "        self.img_size = 640\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        \"\"\"Converts input images to float tensors.\n",
    "        Args:\n",
    "            data (List): Input data from the request in the form of a list of image tensors.\n",
    "        Returns:\n",
    "            Tensor: single Tensor of shape [BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE]\n",
    "        \"\"\"\n",
    "        images = []\n",
    "\n",
    "        transform = tf.Compose([\n",
    "            tf.ToTensor(),\n",
    "            tf.Resize((self.img_size, self.img_size))\n",
    "        ])\n",
    "\n",
    "        # Method 1\n",
    "        # image = data[0].get(\"data\") or data[0].get(\"body\")\n",
    "        image = data[0]\n",
    "\n",
    "        if image is None:\n",
    "            warnings.warn(\"data params is none\")\n",
    "            raise Exception(\"no data\")\n",
    "        else:\n",
    "            if isinstance(image, str):\n",
    "                # if the image is a string of bytesarray.\n",
    "                image = base64.b64decode(image)\n",
    "\n",
    "            # If the image is sent as bytesarray\n",
    "            if isinstance(image, (bytearray, bytes)):\n",
    "                image = Image.open(io.BytesIO(image))\n",
    "            else:\n",
    "                # if the image is a list\n",
    "                image = torch.FloatTensor(image)\n",
    "\n",
    "            # force convert to tensor\n",
    "            # and resize to [img_size, img_size]\n",
    "            image = transform(image)\n",
    "\n",
    "            images.append(image)\n",
    "\n",
    "        # convert list of equal-size tensors to single stacked tensor\n",
    "        # has shape BATCH_SIZE x 3 x IMG_SIZE x IMG_SIZE\n",
    "        images_tensor = torch.stack(images).to(self.device)\n",
    "\n",
    "        return images_tensor\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        # perform NMS (nonmax suppression) on model outputs\n",
    "        pred = non_max_suppression(inference_output[0])\n",
    "\n",
    "        # initialize empty list of detections for each image\n",
    "        detections = [[] for _ in range(len(pred))]\n",
    "\n",
    "        for i, image_detections in enumerate(pred):  # axis 0: for each image\n",
    "            for det in image_detections:  # axis 1: for each detection\n",
    "                # x1,y1,x2,y2 in normalized image coordinates (i.e. 0.0-1.0)\n",
    "                xyxy = det[:4] / self.img_size\n",
    "                # confidence value\n",
    "                conf = det[4].item()\n",
    "                # index of predicted class\n",
    "                class_idx = int(det[5].item())\n",
    "                # get label of predicted class\n",
    "                # if missing, then just return class idx\n",
    "                label = self.mapping.get(str(class_idx), class_idx)\n",
    "\n",
    "                detections[i].append({\n",
    "                    \"x1\": xyxy[0].item(),\n",
    "                    \"y1\": xyxy[1].item(),\n",
    "                    \"x2\": xyxy[2].item(),\n",
    "                    \"y2\": xyxy[3].item(),\n",
    "                    \"confidence\": conf,\n",
    "                    \"class\": label\n",
    "                })\n",
    "\n",
    "        # format each detection\n",
    "        return detections\n",
    "\n",
    "\n",
    "def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,\n",
    "                        labels=(), max_det=300):\n",
    "    \"\"\"Runs Non-Maximum Suppression (NMS) on inference results\n",
    "    Returns:\n",
    "         list of detections, on (n,6) tensor per image [xyxy, conf, cls]\n",
    "    \"\"\"\n",
    "\n",
    "    nc = prediction.shape[2] - 5  # number of classes\n",
    "    xc = prediction[..., 4] > conf_thres  # candidates\n",
    "\n",
    "    # Checks\n",
    "    assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'\n",
    "    assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'\n",
    "\n",
    "    # Settings\n",
    "    # (pixels) minimum and maximum box width and height\n",
    "    min_wh, max_wh = 2, 4096\n",
    "    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
    "    time_limit = 10.0  # seconds to quit after\n",
    "    redundant = True  # require redundant detections\n",
    "    multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
    "    merge = False  # use merge-NMS\n",
    "\n",
    "    output = [torch.zeros((0, 6), device=prediction.device)\n",
    "              ] * prediction.shape[0]\n",
    "    for xi, x in enumerate(prediction):  # image index, image inference\n",
    "        # Apply constraints\n",
    "        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
    "        x = x[xc[xi]]  # confidence\n",
    "\n",
    "        # Cat apriori labels if autolabelling\n",
    "        if labels and len(labels[xi]):\n",
    "            l = labels[xi]\n",
    "            v = torch.zeros((len(l), nc + 5), device=x.device)\n",
    "            v[:, :4] = l[:, 1:5]  # box\n",
    "            v[:, 4] = 1.0  # conf\n",
    "            v[range(len(l)), l[:, 0].long() + 5] = 1.0  # cls\n",
    "            x = torch.cat((x, v), 0)\n",
    "\n",
    "        # If none remain process next image\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Compute conf\n",
    "        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
    "\n",
    "        # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
    "        box = xywh2xyxy(x[:, :4])\n",
    "\n",
    "        # Detections matrix nx6 (xyxy, conf, cls)\n",
    "        if multi_label:\n",
    "            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
    "            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)\n",
    "        else:  # best class only\n",
    "            conf, j = x[:, 5:].max(1, keepdim=True)\n",
    "            x = torch.cat((box, conf, j.float()), 1)[\n",
    "                conf.view(-1) > conf_thres]\n",
    "\n",
    "        # Filter by class\n",
    "        if classes is not None:\n",
    "            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
    "\n",
    "        # Apply finite constraint\n",
    "        # if not torch.isfinite(x).all():\n",
    "        #     x = x[torch.isfinite(x).all(1)]\n",
    "\n",
    "        # Check shape\n",
    "        n = x.shape[0]  # number of boxes\n",
    "        if not n:  # no boxes\n",
    "            continue\n",
    "        elif n > max_nms:  # excess boxes\n",
    "            # sort by confidence\n",
    "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n",
    "\n",
    "        # Batched NMS\n",
    "        c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
    "        # boxes (offset by class), scores\n",
    "        boxes, scores = x[:, :4] + c, x[:, 4]\n",
    "        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "        if i.shape[0] > max_det:  # limit detections\n",
    "            i = i[:max_det]\n",
    "        if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\n",
    "            # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)\n",
    "            iou = torchvision.box_iou(\n",
    "                boxes[i], boxes) > iou_thres  # iou matrix\n",
    "            weights = iou * scores[None]  # box weights\n",
    "            x[i, :4] = torch.mm(weights, x[:, :4]).float(\n",
    "            ) / weights.sum(1, keepdim=True)  # merged boxes\n",
    "            if redundant:\n",
    "                i = i[iou.sum(1) > 1]  # require redundancy\n",
    "\n",
    "        output[xi] = x[i]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82097fd3-c832-40da-90a6-8dd30f52ebc6",
   "metadata": {},
   "source": [
    "#### 1.2 Torchserve Model Archiver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8237c2-4dba-4428-9197-9140a393f9e9",
   "metadata": {},
   "source": [
    "It basically create a tar called `{model-name}.mar` from `model-file`, `serialized-file (*.pt)`, `handler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cfffb2d-3a0e-4642-912b-3a3bbe2e5c87",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-model-archiver in /opt/conda/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: enum-compat in /opt/conda/lib/python3.8/site-packages (from torch-model-archiver) (0.0.3)\n",
      "create successfully\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd $(dirname $0)/torchserve\n",
    "base_path=$(pwd)\n",
    "\n",
    "mkdir -p $base_path/model-store && cd $base_path/model-store &&\n",
    "if [ -f $base_path/model-store/helmet_detection.mar ]; then\n",
    "    rm $base_path/model-store/helmet_detection.mar\n",
    "fi\n",
    "\n",
    "pip install torch-model-archiver \n",
    "\n",
    "torch-model-archiver --model-name helmet_detection \\\n",
    "--version 0.1 --serialized-file $base_path/helmet.torchscript.pt \\\n",
    "--handler $base_path/torchserve_handler.py \\\n",
    "--extra-files $base_path/index_to_name.json,$base_path/torchserve_handler.py\n",
    "\n",
    "\n",
    "echo \"create successfully\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53742313-cfe9-4e29-b71e-9d7f92cfb606",
   "metadata": {},
   "source": [
    "#### 1.3 create torchserve config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eca6a9",
   "metadata": {},
   "source": [
    "Feel free to change the parameters:\n",
    "\n",
    "- minWorkers: the minimum number of workers of a model\n",
    "- maxWorkers: the maximum number of workers of a model\n",
    "- batchSize: the batch size of a model\n",
    "- maxBatchDelay: the maximum dalay in msec of a batch of a model\n",
    "- responseTimeout: the timeout in msec of a model's response\n",
    "- defaultVersion: the default version of a model\n",
    "- marName: the mar file name of a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a96fba-15da-44e1-bd4c-877dba5dcee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p torchserve/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55089cd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting torchserve/config/config.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile torchserve/config/config.properties\n",
    "\n",
    "inference_address=http://0.0.0.0:8085\n",
    "management_address=http://0.0.0.0:8081\n",
    "metrics_address=http://0.0.0.0:8082\n",
    "grpc_inference_port=7070\n",
    "grpc_management_port=7071\n",
    "enable_metrics_api=true\n",
    "metrics_format=prometheus\n",
    "number_of_netty_threads=4\n",
    "job_queue_size=10\n",
    "enable_envvars_config=true\n",
    "install_py_dep_per_model=true\n",
    "model_store=/home/model-server/torchserve_mar/helmet_detection/model-store\n",
    "model_snapshot={\"name\":\"startup.cfg\",\"modelCount\":1,\"models\":{\"helmet_detection\":{\"1.0\":{\"defaultVersion\":true,\"marName\":\"helmet_detection.mar\",\"minWorkers\":1,\"maxWorkers\":5,\"batchSize\":4,\"maxBatchDelay\":100,\"responseTimeout\":120}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e99e743-1903-4b7b-972b-06bfe995a12b",
   "metadata": {},
   "source": [
    "#### 1.4 Upload to MinIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49499526-d671-489a-8b9e-2522330c97f3",
   "metadata": {},
   "source": [
    "If you already have the minio storage, you can directly follow the next steps. If not, we also provide a standalone minio deployment guide on the kubernetes clusters.\n",
    "\n",
    "You can use the files from here [https://github.com/xujinheng/kubeflow-manifests/tree/main/website/content/en/docs/kubeflow-tutorial/lab4_minio_deploy], and apply in your clusters.\n",
    "\n",
    "**Notes: Please remember replace your 'storageClassName' within your cluster in the minio-standalone-pvc.yml**\n",
    "\n",
    "`kubectl apply -f minio-standalone-pvc.yml` \n",
    "\n",
    "`kubectl apply -f minio-standalone-service.yml`\n",
    "\n",
    "`kubectl apply -f minio-standalone-deployment.yml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc43bf8",
   "metadata": {},
   "source": [
    "This step uploads `torchserve/model-store`, `torchserve/config` to MinIO buckets\n",
    "\n",
    "You need to find the MINIO\n",
    "- `endpoint_url`\n",
    "- `key_id`\n",
    "- `access_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644fb1ea-3364-48a0-a312-535ceb9b7048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.8/site-packages (1.28.85)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from boto3) (0.7.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.85 in /opt/conda/lib/python3.8/site-packages (from boto3) (1.31.85)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.85->boto3) (1.26.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.85->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.85->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e69a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "\n",
    "os.environ[\"AWS_ENDPOINT_URL\"] = \"http://198.54.17.185:9000\"\n",
    "os.environ[\"AWS_REGION\"] = \"us-east-1\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minioadmin\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin\"\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                    endpoint_url=os.getenv(\"AWS_ENDPOINT_URL\"),\n",
    "                    verify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1b511d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current buckets in s3:\n",
      "[s3.Bucket(name='helmet-bucket')]\n"
     ]
    }
   ],
   "source": [
    "print(\"current buckets in s3:\")\n",
    "print(list(s3.buckets.all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ab383f-65c6-4a8e-bc67-43d8670a34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket_if_not_exists(bucket_name):\n",
    "    existing_buckets = [bucket.name for bucket in s3.buckets.all()]\n",
    "    \n",
    "    if bucket_name not in existing_buckets:\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket '{bucket_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Bucket '{bucket_name}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6acc33f8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'helmet-bucket' already exists.\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'helmet-bucket'\n",
    "create_bucket_if_not_exists(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a1b2f6",
   "metadata": {},
   "source": [
    "Upload files to your bucket_name, and you can also specify `bucket_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb5c40e-808e-49cc-9db5-070fc2b51841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helmet_detection/config/config.properties\n",
      "helmet_detection/model-store/helmet_detection.mar\n"
     ]
    }
   ],
   "source": [
    "curr_path = os.getcwd()\n",
    "base_path = os.path.join(curr_path, \"torchserve\")\n",
    "\n",
    "\n",
    "bucket_path = \"helmet_detection\"\n",
    "\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# upload\n",
    "bucket.upload_file(os.path.join(base_path, \"model-store\", \"helmet_detection.mar\"),\n",
    "                   os.path.join(bucket_path, \"model-store/helmet_detection.mar\"))\n",
    "bucket.upload_file(os.path.join(base_path, \"config\", \"config.properties\"), \n",
    "                   os.path.join(bucket_path, \"config/config.properties\"))\n",
    "\n",
    "# check files \n",
    "for obj in bucket.objects.filter(Prefix=bucket_path):\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3fe861-c578-4f37-9f55-7c00b9b28b82",
   "metadata": {},
   "source": [
    "## 2 KServe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fbbc31-87a5-43f3-b7c6-5254091b8783",
   "metadata": {},
   "source": [
    "#### 2.1 Create Minio service account && secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f14c8-dab6-499c-b16b-0d1aea473ad7",
   "metadata": {},
   "source": [
    "- You will also need to specify the `s3-endpoint`, `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` here\n",
    "- If you are using default user `user@exampe.com/12341234`, please also set a different name for all the <span style=\"color:red\">metadata: name</span> in the yaml file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257bbe98-3840-4993-aa97-0b8802b1baf1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/minio-s3-secret-user created\n",
      "serviceaccount/minio-service-account-user created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat << EOF | kubectl apply -f -\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: minio-s3-secret-user\n",
    "  annotations:\n",
    "     serving.kserve.io/s3-endpoint: \"198.54.17.185:9000\" # replace with your s3 endpoint e.g minio-service.kubeflow:9000\n",
    "     serving.kserve.io/s3-usehttps: \"0\" # by default 1, if testing with minio you can set to 0\n",
    "     serving.kserve.io/s3-region: \"us-east-2\"\n",
    "     serving.kserve.io/s3-useanoncredential: \"false\" # omitting this is the same as false, if true will ignore provided credential and use anonymous credentials\n",
    "type: Opaque\n",
    "stringData: # use \"stringData\" for raw credential string or \"data\" for base64 encoded string\n",
    "  AWS_ACCESS_KEY_ID: minioadmin\n",
    "  AWS_SECRET_ACCESS_KEY: minioadmin\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  name: minio-service-account-user\n",
    "secrets:\n",
    "- name: minio-s3-secret-user\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5503d63-9294-4974-8c81-822fa790d5c5",
   "metadata": {},
   "source": [
    "#### 2.2 Create InferenceService from MinIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81556391",
   "metadata": {},
   "source": [
    "- Set `storageUri` to your `bucket_name/bucket_path`\n",
    "- You may also need to change `metadata: name` and `serviceAccountName` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bb67b2a-e446-46d3-9851-f12f51c49500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kserve.io/helmet-detection-serving created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat << EOF | kubectl apply -f -\n",
    "apiVersion: \"serving.kserve.io/v1beta1\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: \"helmet-detection-serving\"\n",
    "spec:\n",
    "  predictor:\n",
    "    serviceAccountName: minio-service-account-user\n",
    "    model:\n",
    "      modelFormat:\n",
    "        name: pytorch\n",
    "      storageUri: \"s3://helmet-bucket/helmet_detection\"\n",
    "      resources:\n",
    "          requests:\n",
    "            cpu: 50m\n",
    "            memory: 200Mi\n",
    "          limits:\n",
    "            cpu: 100m\n",
    "            memory: 500Mi\n",
    "          # limits:\n",
    "          #   nvidia.com/gpu: \"1\"   # for inference service on GPU\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb8883",
   "metadata": {},
   "source": [
    "#### 2.3 Kubeflow UI\n",
    "\n",
    "Check model logs at [Kubeflow UI -> Models](/models/). There is a need for some time to deploy the inference service. Please wait a few minutes. You can also use 'kubectl get inferenceservice -n your-namespace' or 'kubectl get pod -n your-namespace' to check the KServe deployment and pods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01972d2-becc-45d9-8439-6de84d26caf7",
   "metadata": {},
   "source": [
    "## 3 Test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec065802",
   "metadata": {},
   "source": [
    "#### 3.1 Define a Test_bot for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "212a5487-b3a6-4765-96ef-704fd43c586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.15-py38-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m186.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill>=0.3.7\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dill, multiprocess\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.4\n",
      "    Uninstalling dill-0.3.4:\n",
      "      Successfully uninstalled dill-0.3.4\n",
      "Successfully installed dill-0.3.7 multiprocess-0.70.15\n"
     ]
    }
   ],
   "source": [
    "!pip install multiprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1fe8776-a5b2-4dd5-b364-0d29df632f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import multiprocess as mp\n",
    "import io\n",
    "import base64\n",
    "import PIL.Image as Image\n",
    "# from PIL import Image\n",
    "\n",
    "\n",
    "class Test_bot():\n",
    "    def __init__(self, uri, model, host, session):\n",
    "        self.uri = uri\n",
    "        self.model = model\n",
    "        self.host = host\n",
    "        self.session = session\n",
    "        self.headers = {'Host': self.host, 'Content-Type': \"image/jpeg\", 'Cookie': \"authservice_session=\" + self.session}\n",
    "        self.img = './2.jpg'\n",
    "    \n",
    "    def update_uri(self, uri):\n",
    "        self.uri = uri\n",
    "        \n",
    "    def update_model(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def update_host(self, host):\n",
    "        self.host = host\n",
    "        self.update_headers()\n",
    "        \n",
    "    def update_session(self, session):\n",
    "        self.session = session\n",
    "        self.update_headers()\n",
    "        \n",
    "    def update_headers(self):\n",
    "        self.headers = {'Host': self.host, 'Content-Type': \"image/jpeg\", 'Cookie': \"authservice_session=\" + self.session}\n",
    "        \n",
    "    def get_data(self, x):\n",
    "        if x:\n",
    "            payload = x\n",
    "        else: \n",
    "            payload = self.img\n",
    "        with open(payload, \"rb\") as image:  \n",
    "            f = image.read()\n",
    "            image_data = base64.b64encode(f).decode('utf-8')    \n",
    "\n",
    "        return json.dumps({'instances': [image_data]})\n",
    "\n",
    "    \n",
    "    def predict(self, x=None):\n",
    "        uri = self.uri + '/v1/models/' + self.model + ':predict'\n",
    "        response = requests.request(\"POST\", uri, headers=self.headers, data=self.get_data(x))\n",
    "        return response.text\n",
    "    \n",
    "        \n",
    "    def readiness(self):\n",
    "        # uri = self.uri + '/v1/models/' + self.model\n",
    "        uri = self.uri + '/v1/models/' + self.model\n",
    "        response = requests.get(uri, headers = self.headers, timeout=5)\n",
    "        return response.text\n",
    "\n",
    "    \n",
    "    def explain(self, x=None):\n",
    "        uri = self.uri + '/v1/models/' + self.model + ':explain'\n",
    "        response = requests.post(uri, data=self.get_data(x), headers = self.headers, timeout=10)\n",
    "        return response.text\n",
    "    \n",
    "    def concurrent_predict(self, num=10):\n",
    "        print(\"fire \" + str(num) + \" requests to \" + self.host)\n",
    "        with mp.Pool() as pool:\n",
    "            responses = pool.map(self.predict, range(num))\n",
    "        return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1311d0b7",
   "metadata": {},
   "source": [
    "#### 3.2 Determine host and session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7aadc6",
   "metadata": {},
   "source": [
    "Run the following cell to get `host`, which will be set to the headers in our request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfb136db-76ac-4a9b-81a2-d49529ec2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get inferenceservice helmet-detection-serving -o jsonpath='{.status.url}' | cut -d \"/\" -f 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9709d26a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Use your web browser to login to Kubeflow, and get `Cookies: authservice_session` (Chrome: Developer Tools -> Applications -> Cookies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5079b4e7-ee8f-4388-a130-f5484d7bbf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"helmet_detection\", \"ready\": true}\n",
      "{'predictions': [[{'x1': 0.6902239322662354, 'y1': 0.24169841408729553, 'x2': 0.7481994032859802, 'y2': 0.3332946300506592, 'confidence': 0.8919700980186462, 'class': 'person'}, {'x1': 0.0010159790981560946, 'y1': 0.20112593472003937, 'x2': 0.06262165307998657, 'y2': 0.3038643002510071, 'confidence': 0.8917641043663025, 'class': 'person'}, {'x1': 0.7416869401931763, 'y1': 0.24357035756111145, 'x2': 0.7910981178283691, 'y2': 0.32219842076301575, 'confidence': 0.8897435665130615, 'class': 'person'}, {'x1': 0.6465808153152466, 'y1': 0.30016350746154785, 'x2': 0.6944388151168823, 'y2': 0.37477272748947144, 'confidence': 0.8708840012550354, 'class': 'person'}, {'x1': 0.8362932205200195, 'y1': 0.24196597933769226, 'x2': 0.8901769518852234, 'y2': 0.32216331362724304, 'confidence': 0.8658970594406128, 'class': 'hat'}, {'x1': 0.11715660244226456, 'y1': 0.2785477340221405, 'x2': 0.17345492541790009, 'y2': 0.35548269748687744, 'confidence': 0.8567688465118408, 'class': 'hat'}, {'x1': 0.3243858218193054, 'y1': 0.25397413969039917, 'x2': 0.3961048126220703, 'y2': 0.3512100577354431, 'confidence': 0.8429261445999146, 'class': 'person'}, {'x1': 0.8793138265609741, 'y1': 0.2569176256656647, 'x2': 0.9308530688285828, 'y2': 0.32830461859703064, 'confidence': 0.8314318060874939, 'class': 'hat'}, {'x1': 0.2581776976585388, 'y1': 0.2187282294034958, 'x2': 0.3340612053871155, 'y2': 0.32766249775886536, 'confidence': 0.7706097364425659, 'class': 'person'}, {'x1': 0.23304757475852966, 'y1': 0.255989670753479, 'x2': 0.27176254987716675, 'y2': 0.317762553691864, 'confidence': 0.76960289478302, 'class': 'hat'}, {'x1': 0.5913112163543701, 'y1': 0.29803234338760376, 'x2': 0.6493061780929565, 'y2': 0.3777821362018585, 'confidence': 0.7675313353538513, 'class': 'hat'}, {'x1': 0.596840500831604, 'y1': 0.25816941261291504, 'x2': 0.63739413022995, 'y2': 0.30656352639198303, 'confidence': 0.7505931258201599, 'class': 'hat'}, {'x1': 0.26180964708328247, 'y1': 0.21736088395118713, 'x2': 0.31703171133995056, 'y2': 0.272555410861969, 'confidence': 0.4925423860549927, 'class': 'person'}]]}\n"
     ]
    }
   ],
   "source": [
    "# replace it with the url you used to access Kubeflow\n",
    "bot = Test_bot(uri='http://10.117.233.4',\n",
    "               model='helmet_detection',\n",
    "               # replace it with what is printed above\n",
    "               host='helmet-detection-serving.user.example.com',\n",
    "               # replace it\n",
    "               session='MTY5OTk2ODkwMHxOd3dBTkRKQ1FWQkxSalExVFRZME5VZERWalZMVUVGYU4wRlFXRk5ZUmxaSk5WZFdUVFZKVGxJMlZrMDJWRFpaVHpKYVFUSkpUMUU9fN90VKKKvfTCUK8ygMpGl9eWiGAf7Fo20lkmX6QLoulW')\n",
    "\n",
    "print(bot.readiness()) \n",
    "# print(bot.predict('./2.jpg'))\n",
    "\n",
    "detections = json.loads(bot.predict('./2.jpg'))\n",
    "print(detections)\n",
    "# We didn't implement model explainer, so this result will be 500: Internal Server Error\n",
    "# https://kserve.github.io/website/0.8/modelserving/explainer/explainer/\n",
    "# print(bot.explain(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563245e1-e255-46e2-9348-27a747e86233",
   "metadata": {},
   "source": [
    "### Display model predictions as bounding boxes on the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc214c5-e3bd-4bb9-bdc8-eede88892113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_detections(image_path, detections, figsize=(8, 8)):\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)\n",
    "\n",
    "    scoreArr, nameArr, boxArr = [], [], []\n",
    "\n",
    "    for detection in detections:\n",
    "        score = detection['confidence']\n",
    "        name = detection['class']  #class_names\n",
    "        box = [detection['x1'], detection['y1'], detection['x2'], detection['y2']]      #boxes\n",
    "        scoreArr.append(score)\n",
    "        nameArr.append(name)\n",
    "        boxArr.append(box)\n",
    "\n",
    "    scoreArr, nameArr, boxArr = np.array(scoreArr), np.array(nameArr), np.array(boxArr)\n",
    "\n",
    "    boxes, class_names, scores = boxArr, nameArr, scoreArr\n",
    "    max_boxes, min_score = 18, 0.1\n",
    "    score_split_w = 0.1  # 0.95~1.00\n",
    "    score_split_r = 0.1  #0.90~0.95\n",
    "\n",
    "\n",
    "    for i in range(min(boxes.shape[0], max_boxes)):\n",
    "        if scores[i] >= min_score:\n",
    "            xmin, ymin, xmax, ymax = tuple(boxes[i])\n",
    "\n",
    "            ax = plt.gca()\n",
    "            text = \"{}: {:.2f}\".format(class_names[i], (scores[i]))\n",
    "            w, h = xmax - xmin, ymax - ymin\n",
    "            xmin *= 800\n",
    "            ymin *= 500\n",
    "            w *= 800\n",
    "            h *= 500\n",
    "\n",
    "            if class_names[i] == 'person':\n",
    "                patch = plt.Rectangle(\n",
    "                [xmin, ymin], w, h, fill=False, edgecolor='w', linewidth=3\n",
    "            )\n",
    "            else:\n",
    "                patch = plt.Rectangle(\n",
    "                [xmin, ymin], w, h, fill=False, edgecolor='c', linewidth=3\n",
    "            )\n",
    "\n",
    "        ax.add_patch(patch)\n",
    "\n",
    "        if class_names[i] == 'person':\n",
    "            ax.text(\n",
    "                xmin,\n",
    "                ymin,\n",
    "                text,\n",
    "                bbox={\"facecolor\": 'w', \"alpha\": 1.0},\n",
    "                clip_box=ax.clipbox,\n",
    "                clip_on=True,\n",
    "            )\n",
    "        else:\n",
    "            ax.text(\n",
    "                xmin,\n",
    "                ymin,\n",
    "                text,\n",
    "                bbox={\"facecolor\": 'c', \"alpha\": 0.8},\n",
    "                clip_box=ax.clipbox,\n",
    "                clip_on=True,\n",
    "            )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "image_path = './2.jpg'\n",
    "visualize_detections(image_path, detections['predictions'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d8fcee15318561c421fd029289997adde12df0a6deb462b29cf55fa6694a6d5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
